1.需要引入的包
import org.apache.spark._
import org.apache.spark.rdd.RDD
import org.apache.spark.graphx._
// Create an RDD for the vertices

//初始值 作用不大
val initialMsg = 9999
// 接受数据包是的处理函数 value:(Int,Int)数据格式应该和srcAttr保持一致，msg为接受的值（来源于发送函数的的值）
def vprog(vId:VertexId,value:(Int,Int),msg:Int):(Int,Int)={
    if(msg==initialMsg) value else (msg min value._1,value._1)
}
//向外发送数据的函数  triplet:EdgeTriplet[(Int,Int),Boolean]数据类型由graph的triplet决定
//Iterator[(VertexId,Int)]=》返回类型结构 Iterator[dstId，mag]，dstId表示目标节点Id，msg表示发送出去的值（等于接收函数的msg）
def sendMsg(triplet:EdgeTriplet[(Int,Int),Boolean]):Iterator[(VertexId,Int)]={
    //triplet.srcAttr
    if(triplet.srcAttr._1==triplet.srcAttr._2) Iterator.empty
    else Iterator((triplet.dstId,triplet.srcAttr._1))
}
//当一个节点接受多个值的时候取其中一个值的处理函数
def mergeMsg(msg1:Int,msg2:Int):Int={
    msg1 min msg2
}
val vertices: RDD[(VertexId, (Int, Int))] = sc.parallelize(Array((1L, (7,-1)), (2L, (3,-1)), (3L, (2,-1)), (4L, (6,-1))))
// Create an RDD for edges
val relationships: RDD[Edge[Boolean]] = sc.parallelize(Array(Edge(1L, 2L, true), Edge(1L, 4L, true), Edge(2L, 4L, true), Edge(3L, 1L, true), Edge(3L, 4L, true)))
// Create the graph
val graph = Graph(vertices, relationships)
val minGraph = graph.pregel(initialMsg, Int.MaxValue, EdgeDirection.Out)( vprog, sendMsg, mergeMsg)
minGraph.vertices.collect.foreach{ case (vertexId, (value, original_value))
=> println(value) }