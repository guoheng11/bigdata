<workflow-app xmlns="uri:oozie:workflow:0.4" name="hive_oozie_demo">
    <start to="start"/>
    <action name="start">
        <hive2 xmlns="uri:oozie:hive2-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <jdbc-url>jdbc:hive2://localhost:10000/default</jdbc-url>
            <password>bigdatahadoop</password>
            <script>demo.hql</script>
        </hive2>
        <ok to="export"/>
        <error to="fail"/>
    </action>
    <action name="export">
        <hive2 xmlns="uri:oozie:hive2-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${targetDir}"/>
            </prepare>
            <job-xml>hive-site.xml</job-xml>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <jdbc-url>jdbc:hive2://localhost:10000/default</jdbc-url>
            <password>bigdatahadoop</password>
            <script>export.hql</script>
            <param>outputDir=${targetDir}</param>
        </hive2>
        <ok to="end"/>
        <error to="fail"/>
    </action>
    <kill name="fail">
        <message>ETL task(d) failed, The error message is [${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>
    <end name="end"/>
</workflow-app>